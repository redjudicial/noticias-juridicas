#!/usr/bin/env python3
"""
DiagnÃ³stico completo del sistema de noticias
Analiza todas las fuentes, scrapers, base de datos y frontend
"""

import os
import sys
import requests
import json
import subprocess
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv('APIS_Y_CREDENCIALES.env')

# ConfiguraciÃ³n de Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL', 'https://qfomiierchksyfhxoukj.supabase.co')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

def obtener_noticias_completas():
    """Obtener todas las noticias de la base de datos"""
    try:
        headers = {
            'apikey': SUPABASE_KEY,
            'Authorization': f'Bearer {SUPABASE_KEY}'
        }
        
        response = requests.get(
            f'{SUPABASE_URL}/rest/v1/noticias_juridicas?select=*&order=fecha_publicacion.desc',
            headers=headers
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ Error al obtener noticias: {response.status_code}")
            return []
            
    except Exception as e:
        print(f"âŒ Error en la peticiÃ³n: {e}")
        return []

def analizar_fuentes_detallado():
    """AnÃ¡lisis detallado de cada fuente"""
    print("ğŸ” **ANÃLISIS DETALLADO DE FUENTES**")
    print("=" * 60)
    
    noticias = obtener_noticias_completas()
    
    if not noticias:
        print("âŒ No se pudieron obtener noticias")
        return
    
    # Agrupar por fuente
    fuentes = {}
    fecha_limite = datetime.now().replace(tzinfo=None) - timedelta(hours=24)
    
    for noticia in noticias:
        fuente = noticia['fuente']
        fecha_noticia = datetime.fromisoformat(noticia['fecha_publicacion'].replace('Z', '+00:00')).replace(tzinfo=None)
        
        if fuente not in fuentes:
            fuentes[fuente] = {
                'total': 0,
                'recientes': 0,
                'primera_fecha': None,
                'ultima_fecha': None,
                'ejemplos': []
            }
        
        fuentes[fuente]['total'] += 1
        
        if fecha_noticia > fecha_limite:
            fuentes[fuente]['recientes'] += 1
        
        if not fuentes[fuente]['primera_fecha'] or fecha_noticia < fuentes[fuente]['primera_fecha']:
            fuentes[fuente]['primera_fecha'] = fecha_noticia
        
        if not fuentes[fuente]['ultima_fecha'] or fecha_noticia > fuentes[fuente]['ultima_fecha']:
            fuentes[fuente]['ultima_fecha'] = fecha_noticia
        
        if len(fuentes[fuente]['ejemplos']) < 3:
            fuentes[fuente]['ejemplos'].append(noticia['titulo'][:50])
    
    # Lista de fuentes esperadas
    fuentes_esperadas = [
        'poder_judicial', 'contraloria', 'cde', 'tdlc', '1ta', '3ta', 
        'tribunal_ambiental', 'sii', 'tta', 'inapi', 'dt', 'tdpi', 'ministerio_justicia'
    ]
    
    print(f"{'ESTADO':<15} {'FUENTE':<20} {'TOTAL':<6} {'RECIENTES':<10} {'ÃšLTIMA ACTIVIDAD':<20}")
    print("-" * 80)
    
    for fuente in fuentes_esperadas:
        if fuente in fuentes:
            data = fuentes[fuente]
            
            if data['recientes'] > 0:
                estado = "ğŸŸ¢ ACTIVA"
            elif data['total'] > 0:
                estado = "ğŸŸ¡ INACTIVA"
            else:
                estado = "ğŸ”´ SIN DATOS"
            
            ultima = data['ultima_fecha'].strftime('%Y-%m-%d %H:%M') if data['ultima_fecha'] else 'N/A'
            
            print(f"{estado:<15} {fuente:<20} {data['total']:<6} {data['recientes']:<10} {ultima:<20}")
        else:
            print(f"ğŸ”´ SIN DATOS    {fuente:<20} {'0':<6} {'0':<10} {'N/A':<20}")

def verificar_scrapers():
    """Verificar el estado de los scrapers"""
    print(f"\nğŸ”§ **VERIFICACIÃ“N DE SCRAPERS**")
    print("=" * 60)
    
    scrapers = [
        'poder_judicial', 'contraloria', 'cde', 'tdlc', '1ta', '3ta',
        'tribunal_ambiental', 'sii', 'tta', 'inapi', 'dt', 'tdpi', 'ministerio_justicia'
    ]
    
    for scraper in scrapers:
        archivo_test = f"test_{scraper}_scraper.py"
        
        if os.path.exists(archivo_test):
            print(f"âœ… {scraper}: Test disponible")
        else:
            print(f"âŒ {scraper}: Sin test disponible")

def verificar_github_actions():
    """Verificar estado de GitHub Actions"""
    print(f"\nğŸ¤– **ESTADO DE GITHUB ACTIONS**")
    print("=" * 60)
    
    workflow_file = ".github/workflows/scraping_automatico_optimizado.yml"
    
    if os.path.exists(workflow_file):
        print("âœ… Workflow de GitHub Actions encontrado")
        
        # Verificar configuraciÃ³n
        with open(workflow_file, 'r') as f:
            content = f.read()
            
        if "cron: '0 * * * *'" in content:
            print("âœ… ConfiguraciÃ³n 24/7 cada hora correcta")
        else:
            print("âš ï¸ ConfiguraciÃ³n de cron no es 24/7")
    else:
        print("âŒ Workflow de GitHub Actions no encontrado")

def verificar_frontend():
    """Verificar estado del frontend"""
    print(f"\nğŸŒ **ESTADO DEL FRONTEND**")
    print("=" * 60)
    
    archivos_frontend = [
        'frontend/index.html',
        'frontend/js/noticias.js',
        'frontend/css/noticias.css'
    ]
    
    for archivo in archivos_frontend:
        if os.path.exists(archivo):
            print(f"âœ… {archivo}: Encontrado")
        else:
            print(f"âŒ {archivo}: No encontrado")
    
    # Verificar actualizaciÃ³n automÃ¡tica en JS
    if os.path.exists('frontend/js/noticias.js'):
        with open('frontend/js/noticias.js', 'r') as f:
            content = f.read()
            
        if 'setInterval' in content and 'cargarNoticias' in content:
            print("âœ… ActualizaciÃ³n automÃ¡tica configurada")
        else:
            print("âŒ ActualizaciÃ³n automÃ¡tica no configurada")

def verificar_base_datos():
    """Verificar estado de la base de datos"""
    print(f"\nğŸ—„ï¸ **ESTADO DE LA BASE DE DATOS**")
    print("=" * 60)
    
    try:
        headers = {
            'apikey': SUPABASE_KEY,
            'Authorization': f'Bearer {SUPABASE_KEY}'
        }
        
        # Verificar conexiÃ³n
        response = requests.get(
            f'{SUPABASE_URL}/rest/v1/noticias_juridicas?select=count',
            headers=headers
        )
        
        if response.status_code == 200:
            print("âœ… ConexiÃ³n a Supabase exitosa")
            
            # Obtener estadÃ­sticas
            noticias = obtener_noticias_completas()
            if noticias:
                print(f"ğŸ“Š Total noticias: {len(noticias)}")
                
                # Noticias recientes
                fecha_limite = datetime.now().replace(tzinfo=None) - timedelta(hours=24)
                recientes = sum(1 for n in noticias 
                              if datetime.fromisoformat(n['fecha_publicacion'].replace('Z', '+00:00')).replace(tzinfo=None) > fecha_limite)
                
                print(f"ğŸ“ˆ Noticias Ãºltimas 24h: {recientes}")
                
                # Ãšltima noticia
                ultima = noticias[0]['fecha_publicacion']
                print(f"ğŸ• Ãšltima noticia: {ultima[:19]}")
        else:
            print(f"âŒ Error de conexiÃ³n: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Error verificando base de datos: {e}")

def generar_recomendaciones():
    """Generar recomendaciones basadas en el anÃ¡lisis"""
    print(f"\nğŸ’¡ **RECOMENDACIONES**")
    print("=" * 60)
    
    print("1. ğŸš¨ **PRIORIDAD ALTA:**")
    print("   - Arreglar scraper de ContralorÃ­a (errores de hash)")
    print("   - Verificar scraper de SII (posible cambio de estructura)")
    print("   - Revisar scraper de INAPI (sin noticias recientes)")
    
    print("\n2. ğŸ”§ **PRIORIDAD MEDIA:**")
    print("   - Configurar scrapers que nunca han funcionado")
    print("   - Implementar sistema de monitoreo")
    print("   - Optimizar rendimiento del frontend")
    
    print("\n3. ğŸ“Š **PRIORIDAD BAJA:**")
    print("   - Mejorar calidad de resÃºmenes ejecutivos")
    print("   - Implementar notificaciones push")
    print("   - Crear dashboard de mÃ©tricas")

def main():
    """FunciÃ³n principal"""
    print("ğŸ” **DIAGNÃ“STICO COMPLETO DEL SISTEMA DE NOTICIAS**")
    print("=" * 70)
    print(f"ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # Ejecutar diagnÃ³sticos
    analizar_fuentes_detallado()
    verificar_scrapers()
    verificar_github_actions()
    verificar_frontend()
    verificar_base_datos()
    generar_recomendaciones()
    
    print(f"\nâœ… **DIAGNÃ“STICO COMPLETADO**")
    print("=" * 70)
    print("ğŸ“‹ Revisa las recomendaciones y ejecuta el pipeline de optimizaciÃ³n")

if __name__ == "__main__":
    main() 