name: Scraping Automático de Noticias Jurídicas

on:
  schedule:
    # Ejecutar cada 30 minutos
    - cron: '*/30 * * * *'
  workflow_dispatch:  # Permitir ejecución manual

jobs:
  scraping:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout código
      uses: actions/checkout@v4
      
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Configurar variables de entorno
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        echo "SUPABASE_URL=$SUPABASE_URL" >> $GITHUB_ENV
        echo "SUPABASE_SERVICE_ROLE_KEY=$SUPABASE_SERVICE_ROLE_KEY" >> $GITHUB_ENV
        echo "OPENAI_API_KEY=$OPENAI_API_KEY" >> $GITHUB_ENV
        
    - name: Ejecutar scraping automático
      run: |
        python backend/main.py
        
    - name: Notificar resultado
      if: always()
      run: |
        echo "✅ Scraping automático completado - $(date)"
        
    - name: Commit y push cambios (si hay)
      if: success()
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -A
        git diff --quiet && git diff --staged --quiet || git commit -m "Auto-update: Scraping completado $(date)"
        git push
