name: Scraping Automático de Noticias Jurídicas (24/7 - Cada Hora)

on:
  schedule:
    # Ejecutar cada hora, 24/7
    # Cron: minuto hora día mes día_semana
    # 0 = cada hora en el minuto 0
    # * = todos los días del mes
    # * = todos los meses
    # * = todos los días de la semana
    - cron: '0 * * * *'
  
  workflow_dispatch:  # Permitir ejecución manual
    inputs:
      test_mode:
        description: 'Ejecutar en modo prueba (solo 2 fuentes)'
        required: false
        default: 'false'
        type: boolean
      full_run:
        description: 'Ejecutar todas las fuentes (incluye las que no funcionan)'
        required: false
        default: 'false'
        type: boolean

jobs:
  scraping-noticias:
    runs-on: ubuntu-latest
    timeout-minutes: 25  # Aumentado para evitar cortes en ejecuciones más lentas
    
    steps:
    - name: Checkout código
      uses: actions/checkout@v4
      
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
        
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Configurar variables de entorno
      run: |
        echo "Configurando variables de entorno..."
        echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
        echo "SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }}" >> $GITHUB_ENV
        echo "SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" >> $GITHUB_ENV
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV

    - name: Verificar configuración de Supabase (previo)
      run: |
        echo "🔎 Verificando variables de entorno de Supabase..."
        echo "SUPABASE_URL=$SUPABASE_URL"
        echo "Probando lectura de conteo de noticias (previo)..."
        curl -s -H "apikey: $SUPABASE_ANON_KEY" -H "Authorization: Bearer $SUPABASE_ANON_KEY" \
          "$SUPABASE_URL/rest/v1/noticias_juridicas?select=count" | cat
        
    - name: Crear archivo de configuración
      run: |
        cat > APIS_Y_CREDENCIALES.env << EOF
        SUPABASE_URL=${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }}
        SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        EOF
        
    - name: Ejecutar scraping optimizado
      run: |
        echo "🚀 Iniciando scraping automático 24/7 (cada hora)..."
        echo "📅 Fecha: $(date)"
        echo "⏰ Hora: $(date +%H:%M:%S)"
        
        if [ "${{ github.event.inputs.test_mode }}" = "true" ]; then
          echo "🧪 MODO PRUEBA: Solo fuentes funcionando"
          python3 backend/main.py --once --test-mode --max-noticias 5
        elif [ "${{ github.event.inputs.full_run }}" = "true" ]; then
          echo "🏭 MODO COMPLETO: Todas las fuentes"
          python3 backend/main.py --once --max-noticias 10
        else
          echo "⚡ MODO OPTIMIZADO: Solo fuentes funcionando, pocas noticias"
          python3 backend/main.py --once --working-only --max-noticias 3
        fi

    - name: Diagnóstico Supabase (post-scraping)
      run: |
        echo "📊 Verificando conteo de noticias (posterior al scraping)..."
        curl -s -H "apikey: $SUPABASE_ANON_KEY" -H "Authorization: Bearer $SUPABASE_ANON_KEY" \
          "$SUPABASE_URL/rest/v1/noticias_juridicas?select=count" | cat

    - name: Test de conexión a Supabase (detallado)
      if: always()
      run: |
        echo "🧪 Ejecutando test detallado de conexión a Supabase..."
        python3 test_supabase_connection.py || true
        
    - name: Verificar resultados
      run: |
        echo "📊 Verificando resultados del scraping..."
        # Verificación rápida
        echo "✅ Scraping completado exitosamente"
        
    - name: Limpiar archivos temporales
      if: always()
      run: |
        echo "🧹 Limpiando archivos temporales..."
        rm -f APIS_Y_CREDENCIALES.env
        rm -f *.log
        rm -f scraping.pid
        
  # Job de monitoreo simplificado (solo si es necesario)
  monitoreo-rapido:
    runs-on: ubuntu-latest
    needs: scraping-noticias
    if: github.event.inputs.full_run == 'true' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Checkout código
      uses: actions/checkout@v4
      
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Configurar variables de entorno
      run: |
        echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> $GITHUB_ENV
        echo "SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }}" >> $GITHUB_ENV
        echo "SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" >> $GITHUB_ENV
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
        
    - name: Generar estadísticas rápidas
      run: |
        echo "📈 Generando estadísticas rápidas..."
        python3 backend/main.py --stats --quick 