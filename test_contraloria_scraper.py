#!/usr/bin/env python3
"""
Script para probar el scraper de Contralor√≠a
"""

import sys
import os

# Agregar el directorio del proyecto al path
sys.path.append(os.path.dirname(__file__))

def test_contraloria_scraper():
    """Probar el scraper de Contralor√≠a"""
    try:
        from backend.scrapers.fuentes.contraloria import ContraloriaScraper
        
        print("üß™ PROBANDO SCRAPER DE CONTRALOR√çA")
        print("=" * 50)
        
        # Crear instancia del scraper
        scraper = ContraloriaScraper()
        
        # Probar obtenci√≥n de enlaces
        print("üîç Obteniendo enlaces de noticias...")
        enlaces = scraper.get_noticias_recientes(5)
        
        if enlaces:
            print(f"‚úÖ Encontrados {len(enlaces)} enlaces:")
            for i, enlace in enumerate(enlaces, 1):
                print(f"   {i}. {enlace['titulo'][:60]}...")
                print(f"      URL: {enlace['url']}")
                print()
            
            # Probar extracci√≥n de una noticia completa
            if enlaces:
                print("üìÑ Extrayendo noticia completa...")
                noticia = scraper.get_noticia_completa(enlaces[0]['url'], enlaces[0]['titulo'])
                
                if noticia:
                    print("‚úÖ Noticia extra√≠da exitosamente:")
                    print(f"   T√≠tulo: {noticia.titulo}")
                    print(f"   Fuente: {noticia.fuente_nombre_completo}")
                    print(f"   Fecha: {noticia.fecha_publicacion}")
                    print(f"   Categor√≠a: {noticia.categoria}")
                    print(f"   Jurisdicci√≥n: {noticia.jurisdiccion}")
                    print(f"   Contenido: {len(noticia.cuerpo_completo)} caracteres")
                    print(f"   URL: {noticia.url_origen}")
                else:
                    print("‚ùå No se pudo extraer la noticia completa")
        else:
            print("‚ùå No se encontraron enlaces de noticias")
            
    except ImportError as e:
        print(f"‚ùå Error importando scraper de Contralor√≠a: {e}")
    except Exception as e:
        print(f"‚ùå Error probando scraper de Contralor√≠a: {e}")

def test_contraloria_scraping_completo():
    """Probar scraping completo de Contralor√≠a"""
    try:
        from backend.scrapers.fuentes.contraloria import ContraloriaScraper
        
        print("\nüöÄ PROBANDO SCRAPING COMPLETO DE CONTRALOR√çA")
        print("=" * 50)
        
        scraper = ContraloriaScraper()
        noticias = scraper.scrape_noticias_recientes(3)
        
        if noticias:
            print(f"‚úÖ Scraping completado: {len(noticias)} noticias extra√≠das")
            for i, noticia in enumerate(noticias, 1):
                print(f"\nüì∞ Noticia {i}:")
                print(f"   T√≠tulo: {noticia.titulo}")
                print(f"   Fuente: {noticia.fuente_nombre_completo}")
                print(f"   Fecha: {noticia.fecha_publicacion}")
                print(f"   Categor√≠a: {noticia.categoria}")
                print(f"   Jurisdicci√≥n: {noticia.jurisdiccion}")
                print(f"   Contenido: {len(noticia.cuerpo_completo)} caracteres")
        else:
            print("‚ùå No se extrajeron noticias")
            
    except Exception as e:
        print(f"‚ùå Error en scraping completo: {e}")

if __name__ == "__main__":
    test_contraloria_scraper()
    test_contraloria_scraping_completo() 