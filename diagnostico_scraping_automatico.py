#!/usr/bin/env python3
"""
Diagn√≥stico del sistema de scraping autom√°tico
Verifica por qu√© no se est√°n agregando nuevas noticias
"""

import os
import sys
import requests
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv('APIS_Y_CREDENCIALES.env')

# Configuraci√≥n de Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL', 'https://qfomiierchksyfhxoukj.supabase.co')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

def obtener_noticias_recientes():
    """Obtener noticias de los √∫ltimos 7 d√≠as"""
    try:
        headers = {
            'apikey': SUPABASE_KEY,
            'Authorization': f'Bearer {SUPABASE_KEY}'
        }
        
        # Obtener noticias de los √∫ltimos 7 d√≠as
        fecha_limite = (datetime.now() - timedelta(days=7)).isoformat()
        
        response = requests.get(
            f'{SUPABASE_URL}/rest/v1/noticias_juridicas?select=*&fecha_publicacion=gte.{fecha_limite}&order=fecha_publicacion.desc',
            headers=headers
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ùå Error al obtener noticias: {response.status_code}")
            return []
            
    except Exception as e:
        print(f"‚ùå Error en la petici√≥n: {e}")
        return []

def analizar_actividad_reciente():
    """Analizar la actividad reciente de scraping"""
    print("üîç **DIAGN√ìSTICO DEL SCRAPING AUTOM√ÅTICO**")
    print("=" * 60)
    
    # Obtener noticias recientes
    noticias_recientes = obtener_noticias_recientes()
    
    if not noticias_recientes:
        print("‚ùå No se pudieron obtener noticias recientes")
        return
    
    print(f"üìä Total noticias en los √∫ltimos 7 d√≠as: {len(noticias_recientes)}")
    
    # Analizar por fecha
    fechas = {}
    fuentes = {}
    
    for noticia in noticias_recientes:
        fecha = noticia['fecha_publicacion'][:10]  # Solo la fecha
        fuente = noticia['fuente']
        
        fechas[fecha] = fechas.get(fecha, 0) + 1
        fuentes[fuente] = fuentes.get(fuente, 0) + 1
    
    print(f"\nüìÖ **ACTIVIDAD POR FECHA:**")
    print("-" * 40)
    for fecha in sorted(fechas.keys(), reverse=True):
        print(f"  {fecha}: {fechas[fecha]} noticias")
    
    print(f"\nüì∞ **ACTIVIDAD POR FUENTE:**")
    print("-" * 40)
    for fuente, cantidad in sorted(fuentes.items(), key=lambda x: x[1], reverse=True):
        print(f"  {fuente}: {cantidad} noticias")
    
    # Verificar la √∫ltima noticia
    if noticias_recientes:
        ultima_noticia = noticias_recientes[0]
        fecha_ultima = datetime.fromisoformat(ultima_noticia['fecha_publicacion'].replace('Z', '+00:00'))
        tiempo_transcurrido = datetime.now(fecha_ultima.tzinfo) - fecha_ultima
        
        print(f"\n‚è∞ **√öLTIMA NOTICIA:**")
        print("-" * 40)
        print(f"  T√≠tulo: {ultima_noticia['titulo'][:50]}...")
        print(f"  Fuente: {ultima_noticia['fuente']}")
        print(f"  Fecha: {fecha_ultima.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  Tiempo transcurrido: {tiempo_transcurrido}")
        
        if tiempo_transcurrido.days > 1:
            print("‚ö†Ô∏è  ¬°ALERTA! No hay noticias nuevas en m√°s de 1 d√≠a")
        elif tiempo_transcurrido.total_seconds() > 12 * 3600:  # 12 horas en segundos
            print("‚ö†Ô∏è  ¬°ALERTA! No hay noticias nuevas en m√°s de 12 horas")

def verificar_github_actions():
    """Verificar el estado de GitHub Actions"""
    print(f"\nü§ñ **ESTADO DE GITHUB ACTIONS**")
    print("-" * 40)
    
    # Verificar horario actual
    ahora = datetime.now()
    hora_chile = ahora.hour
    dia_semana = ahora.weekday()  # 0=Lunes, 6=Domingo
    
    print(f"  Fecha actual: {ahora.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  Hora en Chile: {hora_chile}:{ahora.minute:02d}")
    print(f"  D√≠a de la semana: {['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo'][dia_semana]}")
    
    # Verificar si est√° en horario h√°bil
    en_horario_habil = (dia_semana < 5 and 9 <= hora_chile <= 17)
    
    if en_horario_habil:
        print("‚úÖ En horario h√°bil (GitHub Actions deber√≠a ejecutarse)")
    else:
        print("‚ùå Fuera de horario h√°bil (GitHub Actions NO se ejecuta)")
        print("   Horario configurado: Lunes-Viernes, 9:00-17:00 hora Chile")
    
    # Verificar configuraci√≥n del cron
    print(f"\nüìã **CONFIGURACI√ìN ACTUAL:**")
    print("-" * 40)
    print("  Cron: '0,30 12-20 * * 1-5'")
    print("  Significado: Cada 30 min, 12-20 UTC, Lunes-Viernes")
    print("  Equivale a: Cada 30 min, 9:00-17:00 hora Chile, Lunes-Viernes")

def sugerir_soluciones():
    """Sugerir soluciones al problema"""
    print(f"\nüí° **SOLUCIONES SUGERIDAS**")
    print("-" * 40)
    
    ahora = datetime.now()
    dia_semana = ahora.weekday()
    
    if dia_semana >= 5:  # Fin de semana
        print("1. üåÖ Ejecutar scraping manualmente:")
        print("   - Ir a GitHub > Actions > scraping_automatico_optimizado")
        print("   - Hacer clic en 'Run workflow'")
        print("   - Seleccionar 'test_mode: true' para prueba r√°pida")
    
    print("2. üîß Modificar horario de ejecuci√≥n:")
    print("   - Cambiar cron a ejecutar tambi√©n fines de semana")
    print("   - O extender horario a 24/7")
    
    print("3. üöÄ Ejecutar scraping localmente:")
    print("   python3 backend/main.py --once --working-only --max-noticias 5")
    
    print("4. üìä Verificar logs de GitHub Actions:")
    print("   - Revisar si hay errores en las √∫ltimas ejecuciones")
    print("   - Verificar si las credenciales est√°n correctas")

def ejecutar_scraping_manual():
    """Ejecutar scraping manual para probar"""
    print(f"\nüöÄ **EJECUTANDO SCRAPING MANUAL**")
    print("-" * 40)
    
    try:
        import subprocess
        resultado = subprocess.run([
            'python3', 'backend/main.py', '--once', '--working-only', '--max-noticias', '3'
        ], capture_output=True, text=True, timeout=300)
        
        print("‚úÖ Scraping manual completado")
        print(f"Salida: {resultado.stdout}")
        
        if resultado.stderr:
            print(f"Errores: {resultado.stderr}")
            
    except subprocess.TimeoutExpired:
        print("‚ùå Timeout: El scraping tard√≥ m√°s de 5 minutos")
    except Exception as e:
        print(f"‚ùå Error ejecutando scraping: {e}")

def main():
    """Funci√≥n principal"""
    print("üîç **DIAGN√ìSTICO COMPLETO DEL SISTEMA DE SCRAPING**")
    print("=" * 70)
    
    # Analizar actividad reciente
    analizar_actividad_reciente()
    
    # Verificar GitHub Actions
    verificar_github_actions()
    
    # Sugerir soluciones
    sugerir_soluciones()
    
    # Preguntar si ejecutar scraping manual
    print(f"\n‚ùì ¬øDeseas ejecutar un scraping manual para probar? (s/n): ", end="")
    respuesta = input().lower().strip()
    
    if respuesta in ['s', 'si', 's√≠', 'y', 'yes']:
        ejecutar_scraping_manual()
    
    print(f"\n‚úÖ **DIAGN√ìSTICO COMPLETADO**")
    print("=" * 70)

if __name__ == "__main__":
    main() 