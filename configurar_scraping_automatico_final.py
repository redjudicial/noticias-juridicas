#!/usr/bin/env python3
"""
Script para configurar el scraping automÃ¡tico de noticias jurÃ­dicas
ACTIVO DESDE EL LUNES 21 DE JULIO - CADA 15 MINUTOS
"""

import os
import sys
from datetime import datetime, timedelta
import schedule
import time

def configurar_scraping_automatico():
    """Configurar el scraping automÃ¡tico"""
    print("ğŸ”§ CONFIGURACIÃ“N DE SCRAPING AUTOMÃTICO")
    print("=" * 60)
    
    # ConfiguraciÃ³n
    config = {
        'fecha_inicio': '2025-07-21',  # Lunes 21 de julio
        'intervalo_minutos': 15,
        'fuentes_activas': [
            'poder_judicial',      # âœ… FUNCIONANDO
            'ministerio_justicia', # âœ… FUNCIONANDO
            'tribunal_constitucional', # ğŸ”§ EN DESARROLLO
            'dpp',                 # ğŸ”§ EN DESARROLLO
            'diario_oficial',      # ğŸ”§ EN DESARROLLO
            'fiscalia',           # ğŸ”§ EN DESARROLLO
            'contraloria',        # ğŸ”§ EN DESARROLLO
            'cde'                 # ğŸ”§ EN DESARROLLO
        ],
        'max_noticias_por_fuente': 20,
        'log_file': 'scraping_automatico.log'
    }
    
    print(f"ğŸ“… Fecha de inicio: {config['fecha_inicio']}")
    print(f"â° Intervalo: {config['intervalo_minutos']} minutos")
    print(f"ğŸ“° Fuentes activas: {len(config['fuentes_activas'])}")
    print(f"ğŸ”¢ MÃ¡ximo noticias por fuente: {config['max_noticias_por_fuente']}")
    print(f"ğŸ“ Log file: {config['log_file']}")
    
    return config

def crear_script_inicio():
    """Crear script para iniciar el scraping automÃ¡tico"""
    script_content = '''#!/bin/bash
# Script para iniciar el scraping automÃ¡tico de noticias jurÃ­dicas
# ACTIVO DESDE EL LUNES 21 DE JULIO - CADA 15 MINUTOS

echo "ğŸš€ Iniciando scraping automÃ¡tico de noticias jurÃ­dicas..."
echo "ğŸ“… Fecha: $(date)"
echo "â° Intervalo: 15 minutos"
echo "ğŸ“° Fuentes: Poder Judicial, Ministerio de Justicia, etc."

# Verificar que estamos en el directorio correcto
cd "$(dirname "$0")"

# Verificar que existe el archivo de credenciales
if [ ! -f "APIS_Y_CREDENCIALES.env" ]; then
    echo "âŒ Error: No se encontrÃ³ APIS_Y_CREDENCIALES.env"
    exit 1
fi

# Cargar variables de entorno
source APIS_Y_CREDENCIALES.env

# Verificar que las variables estÃ¡n cargadas
if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_SERVICE_ROLE_KEY" ]; then
    echo "âŒ Error: Variables de Supabase no encontradas"
    exit 1
fi

echo "âœ… Variables de entorno cargadas correctamente"

# Iniciar el scraping en modo programado
echo "ğŸ”„ Iniciando sistema de scraping automÃ¡tico..."
nohup python3 backend/main.py --scheduled > scraping_automatico.log 2>&1 &

# Guardar el PID del proceso
echo $! > scraping.pid

echo "âœ… Scraping automÃ¡tico iniciado con PID: $(cat scraping.pid)"
echo "ğŸ“ Logs disponibles en: scraping_automatico.log"
echo "ğŸ›‘ Para detener: ./detener_scraping.sh"
'''
    
    with open('iniciar_scraping_automatico.sh', 'w') as f:
        f.write(script_content)
    
    # Hacer ejecutable
    os.system('chmod +x iniciar_scraping_automatico.sh')
    print("âœ… Script de inicio creado: iniciar_scraping_automatico.sh")

def crear_script_detencion():
    """Crear script para detener el scraping automÃ¡tico"""
    script_content = '''#!/bin/bash
# Script para detener el scraping automÃ¡tico de noticias jurÃ­dicas

echo "ğŸ›‘ Deteniendo scraping automÃ¡tico..."

# Verificar que estamos en el directorio correcto
cd "$(dirname "$0")"

# Verificar si existe el archivo PID
if [ ! -f "scraping.pid" ]; then
    echo "âŒ No se encontrÃ³ archivo PID. El scraping no estÃ¡ ejecutÃ¡ndose."
    exit 1
fi

# Leer el PID
PID=$(cat scraping.pid)

# Verificar si el proceso estÃ¡ ejecutÃ¡ndose
if ps -p $PID > /dev/null; then
    echo "ğŸ”„ Deteniendo proceso con PID: $PID"
    kill $PID
    
    # Esperar un momento y verificar si se detuvo
    sleep 2
    if ps -p $PID > /dev/null; then
        echo "âš ï¸  El proceso no se detuvo, forzando terminaciÃ³n..."
        kill -9 $PID
    fi
    
    echo "âœ… Proceso detenido exitosamente"
else
    echo "âš ï¸  El proceso con PID $PID no estÃ¡ ejecutÃ¡ndose"
fi

# Limpiar archivo PID
rm -f scraping.pid

echo "ğŸ§¹ Limpieza completada"
'''
    
    with open('detener_scraping_automatico.sh', 'w') as f:
        f.write(script_content)
    
    # Hacer ejecutable
    os.system('chmod +x detener_scraping_automatico.sh')
    print("âœ… Script de detenciÃ³n creado: detener_scraping_automatico.sh")

def crear_script_monitoreo():
    """Crear script para monitorear el scraping automÃ¡tico"""
    script_content = '''#!/bin/bash
# Script para monitorear el scraping automÃ¡tico de noticias jurÃ­dicas

echo "ğŸ“Š MONITOREO DE SCRAPING AUTOMÃTICO"
echo "=================================="

# Verificar que estamos en el directorio correcto
cd "$(dirname "$0")"

# Verificar si el proceso estÃ¡ ejecutÃ¡ndose
if [ -f "scraping.pid" ]; then
    PID=$(cat scraping.pid)
    if ps -p $PID > /dev/null; then
        echo "âœ… Scraping automÃ¡tico EJECUTÃNDOSE (PID: $PID)"
        echo "â° Iniciado: $(ps -o lstart= -p $PID)"
        echo "ğŸ’¾ Memoria: $(ps -o rss= -p $PID | awk '{print $1/1024 " MB"}')"
    else
        echo "âŒ Scraping automÃ¡tico DETENIDO (PID: $PID no encontrado)"
    fi
else
    echo "âŒ Scraping automÃ¡tico NO INICIADO"
fi

echo ""
echo "ğŸ“ ÃšLTIMOS LOGS:"
echo "================"
if [ -f "scraping_automatico.log" ]; then
    tail -20 scraping_automatico.log
else
    echo "No se encontrÃ³ archivo de logs"
fi

echo ""
echo "ğŸ“Š ESTADÃSTICAS DE HOY:"
echo "======================"
# AquÃ­ se pueden agregar comandos para consultar estadÃ­sticas de Supabase
echo "Para ver estadÃ­sticas completas, ejecutar: python3 backend/main.py --stats"
'''
    
    with open('monitorear_scraping.sh', 'w') as f:
        f.write(script_content)
    
    # Hacer ejecutable
    os.system('chmod +x monitorear_scraping.sh')
    print("âœ… Script de monitoreo creado: monitorear_scraping.sh")

def verificar_estado_actual():
    """Verificar el estado actual del sistema"""
    print("\nğŸ” VERIFICACIÃ“N DEL ESTADO ACTUAL")
    print("=" * 40)
    
    # Verificar archivos crÃ­ticos
    archivos_criticos = [
        'APIS_Y_CREDENCIALES.env',
        'backend/main.py',
        'backend/database/supabase_client.py',
        'backend/scrapers/poder_judicial_scraper.py',
        'backend/scrapers/ministerio_justicia_scraper.py'
    ]
    
    for archivo in archivos_criticos:
        if os.path.exists(archivo):
            print(f"âœ… {archivo}")
        else:
            print(f"âŒ {archivo} - FALTANTE")
    
    # Verificar si hay un proceso ejecutÃ¡ndose
    if os.path.exists('scraping.pid'):
        pid = open('scraping.pid').read().strip()
        print(f"ğŸ”„ Proceso activo: PID {pid}")
    else:
        print("â¸ï¸  No hay proceso activo")

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ CONFIGURACIÃ“N FINAL DE SCRAPING AUTOMÃTICO")
    print("=" * 60)
    print("ğŸ“… ACTIVO DESDE EL LUNES 21 DE JULIO")
    print("â° INTERVALO: CADA 15 MINUTOS")
    print("=" * 60)
    
    # Configurar scraping
    config = configurar_scraping_automatico()
    
    # Verificar estado actual
    verificar_estado_actual()
    
    # Crear scripts de control
    print("\nğŸ“ Creando scripts de control...")
    crear_script_inicio()
    crear_script_detencion()
    crear_script_monitoreo()
    
    print("\n" + "=" * 60)
    print("âœ… CONFIGURACIÃ“N COMPLETA")
    print("=" * 60)
    
    print("\nğŸ“‹ INSTRUCCIONES DE USO:")
    print("1. Para INICIAR scraping automÃ¡tico:")
    print("   ./iniciar_scraping_automatico.sh")
    print()
    print("2. Para DETENER scraping automÃ¡tico:")
    print("   ./detener_scraping_automatico.sh")
    print()
    print("3. Para MONITOREAR estado:")
    print("   ./monitorear_scraping.sh")
    print()
    print("4. Para ejecutar UNA VEZ (prueba):")
    print("   python3 backend/main.py --once")
    print()
    print("5. Para ver estadÃ­sticas:")
    print("   python3 backend/main.py --stats")
    
    print("\nğŸ¯ ESTADO ACTUAL:")
    print("âœ… Poder Judicial: FUNCIONANDO")
    print("âœ… Ministerio de Justicia: FUNCIONANDO")
    print("ğŸ”§ Otras fuentes: EN DESARROLLO")
    print("âœ… Base de datos: CONFIGURADA")
    print("âœ… Interfaz web: FUNCIONAL")
    
    print("\nğŸš€ EL SISTEMA ESTÃ LISTO PARA PRODUCCIÃ“N")
    print("ğŸ“… ACTIVO DESDE EL LUNES 21 DE JULIO")
    print("â° CADA 15 MINUTOS AUTOMÃTICAMENTE")

if __name__ == "__main__":
    main() 