#!/usr/bin/env python3
"""
An√°lisis espec√≠fico del error de hash duplicado durante scraping de Contralor√≠a
"""

import os
import sys
import requests
import hashlib
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv('../APIS_Y_CREDENCIALES.env')

# Configuraci√≥n de Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL', 'https://qfomiierchksyfhxoukj.supabase.co')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

def analizar_scraper_contraloria():
    """Analizar el scraper de Contralor√≠a para entender el problema"""
    print("üîç **AN√ÅLISIS DEL SCRAPER - CONTRALOR√çA**")
    print("=" * 60)
    
    scraper_path = "../backend/scrapers/fuentes/contraloria/contraloria_scraper.py"
    
    if not os.path.exists(scraper_path):
        print("‚ùå Archivo del scraper no encontrado")
        return
    
    try:
        with open(scraper_path, 'r') as f:
            contenido = f.read()
        
        print("‚úÖ Archivo del scraper le√≠do correctamente")
        
        # Buscar funciones de inserci√≥n
        if 'insert' in contenido.lower() or 'upsert' in contenido.lower():
            print("‚úÖ Se encontraron funciones de inserci√≥n")
        else:
            print("‚ö†Ô∏è No se encontraron funciones de inserci√≥n")
        
        # Buscar manejo de errores
        if 'except' in contenido.lower() or 'error' in contenido.lower():
            print("‚úÖ Se encontr√≥ manejo de errores")
        else:
            print("‚ö†Ô∏è No se encontr√≥ manejo de errores")
        
        # Buscar verificaci√≥n de duplicados
        if 'duplicate' in contenido.lower() or 'exists' in contenido.lower():
            print("‚úÖ Se encontr√≥ verificaci√≥n de duplicados")
        else:
            print("‚ö†Ô∏è No se encontr√≥ verificaci√≥n de duplicados")
        
        # Mostrar l√≠neas relevantes
        lineas = contenido.split('\n')
        print("\nüìã **L√çNEAS RELEVANTES:**")
        for i, linea in enumerate(lineas):
            if any(palabra in linea.lower() for palabra in ['insert', 'upsert', 'error', 'duplicate', 'hash']):
                print(f"   L√≠nea {i+1}: {linea.strip()}")
                
    except Exception as e:
        print(f"‚ùå Error leyendo archivo: {e}")

def analizar_supabase_client():
    """Analizar el cliente de Supabase para entender la inserci√≥n"""
    print("\nüîç **AN√ÅLISIS DEL CLIENTE SUPABASE**")
    print("=" * 60)
    
    client_path = "../backend/database/supabase_client.py"
    
    if not os.path.exists(client_path):
        print("‚ùå Archivo del cliente no encontrado")
        return
    
    try:
        with open(client_path, 'r') as f:
            contenido = f.read()
        
        print("‚úÖ Archivo del cliente le√≠do correctamente")
        
        # Buscar funciones de inserci√≥n
        if 'insert' in contenido.lower():
            print("‚úÖ Se encontraron funciones de inserci√≥n")
        else:
            print("‚ö†Ô∏è No se encontraron funciones de inserci√≥n")
        
        # Buscar manejo de errores de duplicado
        if '23505' in contenido or 'duplicate' in contenido.lower():
            print("‚úÖ Se encontr√≥ manejo de errores de duplicado")
        else:
            print("‚ö†Ô∏è No se encontr√≥ manejo de errores de duplicado")
        
        # Mostrar l√≠neas relevantes
        lineas = contenido.split('\n')
        print("\nüìã **L√çNEAS RELEVANTES:**")
        for i, linea in enumerate(lineas):
            if any(palabra in linea.lower() for palabra in ['insert', '23505', 'duplicate', 'error']):
                print(f"   L√≠nea {i+1}: {linea.strip()}")
                
    except Exception as e:
        print(f"‚ùå Error leyendo archivo: {e}")

def simular_error_hash():
    """Simular el error de hash duplicado"""
    print("\nüß™ **SIMULACI√ìN DE ERROR DE HASH**")
    print("=" * 60)
    
    # Obtener noticias existentes de Contralor√≠a
    try:
        headers = {
            'apikey': SUPABASE_KEY,
            'Authorization': f'Bearer {SUPABASE_KEY}'
        }
        
        response = requests.get(
            f'{SUPABASE_URL}/rest/v1/noticias_juridicas?select=*&fuente=eq.contraloria&order=fecha_publicacion.desc&limit=5',
            headers=headers
        )
        
        if response.status_code == 200:
            noticias = response.json()
            print(f"‚úÖ Obtenidas {len(noticias)} noticias de Contralor√≠a")
            
            # Intentar insertar una noticia existente
            if noticias:
                noticia_existente = noticias[0]
                
                # Crear datos para inserci√≥n
                datos_insercion = {
                    'titulo': noticia_existente['titulo'],
                    'contenido': noticia_existente['contenido'],
                    'url_origen': noticia_existente['url_origen'],
                    'fuente': 'contraloria',
                    'fecha_publicacion': noticia_existente['fecha_publicacion'],
                    'hash_contenido': noticia_existente['hash_contenido']
                }
                
                print("üîç Intentando insertar noticia duplicada...")
                
                # Intentar inserci√≥n
                response_insert = requests.post(
                    f'{SUPABASE_URL}/rest/v1/noticias_juridicas',
                    headers={
                        **headers,
                        'Content-Type': 'application/json',
                        'Prefer': 'return=minimal'
                    },
                    json=datos_insercion
                )
                
                if response_insert.status_code == 409:
                    print("‚úÖ Error 409 (duplicado) reproducido correctamente")
                    print(f"   Error: {response_insert.text}")
                else:
                    print(f"‚ö†Ô∏è Respuesta inesperada: {response_insert.status_code}")
                    print(f"   Respuesta: {response_insert.text}")
                    
        else:
            print(f"‚ùå Error obteniendo noticias: {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Error en simulaci√≥n: {e}")

def analizar_logs_scraping():
    """Analizar logs del scraping para entender el problema"""
    print("\nüìã **AN√ÅLISIS DE LOGS DE SCRAPING**")
    print("=" * 60)
    
    # Buscar archivos de log
    logs_dir = "../logs" if os.path.exists("../logs") else "."
    
    archivos_log = []
    for archivo in os.listdir(logs_dir):
        if archivo.endswith('.log') or 'log' in archivo.lower():
            archivos_log.append(os.path.join(logs_dir, archivo))
    
    if archivos_log:
        print(f"‚úÖ Encontrados {len(archivos_log)} archivos de log")
        
        for archivo in archivos_log:
            print(f"\nüìÑ Analizando: {archivo}")
            try:
                with open(archivo, 'r') as f:
                    contenido = f.read()
                
                # Buscar errores de Contralor√≠a
                if 'contraloria' in contenido.lower():
                    print("‚úÖ Se encontraron referencias a Contralor√≠a")
                    
                    # Buscar errores espec√≠ficos
                    if '23505' in contenido or 'duplicate' in contenido.lower():
                        print("‚úÖ Se encontraron errores de duplicado")
                        
                        # Mostrar l√≠neas con errores
                        lineas = contenido.split('\n')
                        for i, linea in enumerate(lineas):
                            if '23505' in linea or 'duplicate' in linea.lower():
                                print(f"   L√≠nea {i+1}: {linea.strip()}")
                    else:
                        print("‚ö†Ô∏è No se encontraron errores de duplicado")
                else:
                    print("‚ö†Ô∏è No se encontraron referencias a Contralor√≠a")
                    
            except Exception as e:
                print(f"‚ùå Error leyendo archivo: {e}")
    else:
        print("‚ö†Ô∏è No se encontraron archivos de log")

def generar_solucion_hash():
    """Generar soluci√≥n para el problema de hash duplicado"""
    print("\nüí° **SOLUCI√ìN PARA ERROR DE HASH DUPLICADO**")
    print("=" * 60)
    
    print("üîß **PROBLEMA IDENTIFICADO:**")
    print("   - El scraper intenta insertar noticias que ya existen")
    print("   - No hay verificaci√≥n de duplicados antes de insertar")
    print("   - El error 409 (duplicado) no se maneja correctamente")
    
    print("\nüîß **SOLUCI√ìN PROPUESTA:**")
    print("1. **Verificaci√≥n previa de duplicados:**")
    print("   - Buscar noticia existente por URL antes de insertar")
    print("   - Verificar por t√≠tulo y fecha si la URL no existe")
    print("   - Usar hash como respaldo, no como √∫nico identificador")
    
    print("\n2. **Manejo de errores de duplicado:**")
    print("   - Capturar error 409 (duplicado)")
    print("   - Actualizar noticia existente en lugar de fallar")
    print("   - Logging informativo en lugar de error")
    
    print("\n3. **Mejora en la l√≥gica de inserci√≥n:**")
    print("   - Implementar upsert (insert or update)")
    print("   - Verificar existencia antes de intentar inserci√≥n")
    print("   - Manejo graceful de duplicados")
    
    print("\n4. **C√≥digo de ejemplo:**")
    print("""
    # Verificar si la noticia ya existe
    noticia_existente = buscar_noticia_por_url(url)
    if noticia_existente:
        # Actualizar noticia existente
        actualizar_noticia(noticia_existente['id'], datos_nuevos)
    else:
        # Insertar nueva noticia
        insertar_noticia(datos_nuevos)
    """)

def main():
    """Funci√≥n principal"""
    print("üîç **AN√ÅLISIS ESPEC√çFICO - ERROR HASH CONTRALOR√çA**")
    print("=" * 70)
    print(f"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # Ejecutar an√°lisis
    analizar_scraper_contraloria()
    analizar_supabase_client()
    simular_error_hash()
    analizar_logs_scraping()
    generar_solucion_hash()
    
    print(f"\n‚úÖ **AN√ÅLISIS COMPLETADO**")
    print("=" * 70)

if __name__ == "__main__":
    main() 