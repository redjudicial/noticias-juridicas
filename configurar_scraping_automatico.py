#!/usr/bin/env python3
"""
Script para configurar el scraping automÃ¡tico de noticias jurÃ­dicas
ComenzarÃ¡ el lunes 21 de julio, cada 15 minutos
"""

import os
import sys
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv('APIS_Y_CREDENCIALES.env')

def configurar_scraping_automatico():
    """Configurar el sistema de scraping automÃ¡tico"""
    
    print("ğŸ”§ Configurando scraping automÃ¡tico de noticias jurÃ­dicas")
    print("=" * 60)
    
    # Fecha de inicio: Lunes 21 de julio
    fecha_inicio = datetime(2025, 7, 21, 9, 0, 0, tzinfo=timezone.utc)  # 9:00 AM UTC
    ahora = datetime.now(timezone.utc)
    
    print(f"ğŸ“… Fecha actual: {ahora.strftime('%d/%m/%Y %H:%M:%S')}")
    print(f"ğŸš€ Fecha de inicio: {fecha_inicio.strftime('%d/%m/%Y %H:%M:%S')}")
    
    if ahora < fecha_inicio:
        dias_restantes = (fecha_inicio - ahora).days
        horas_restantes = ((fecha_inicio - ahora).seconds // 3600)
        print(f"â° Tiempo restante: {dias_restantes} dÃ­as, {horas_restantes} horas")
    else:
        print("âœ… Â¡Ya es momento de comenzar el scraping automÃ¡tico!")
    
    print("\nğŸ“‹ ConfiguraciÃ³n del sistema:")
    print("   â€¢ Intervalo: 15 minutos")
    print("   â€¢ Fuentes: 8 fuentes oficiales")
    print("   â€¢ Base de datos: Supabase")
    print("   â€¢ Logs: Completos con mÃ©tricas")
    
    print("\nğŸ”§ Comandos para activar:")
    print("   # Para ejecutar manualmente:")
    print("   python3 backend/main.py --once")
    print("")
    print("   # Para activar scraping automÃ¡tico:")
    print("   python3 backend/main.py --scheduled")
    print("")
    print("   # Para ejecutar en background (recomendado):")
    print("   nohup python3 backend/main.py --scheduled > scraping.log 2>&1 &")
    
    print("\nğŸ“Š Monitoreo:")
    print("   # Ver logs en tiempo real:")
    print("   tail -f scraping.log")
    print("")
    print("   # Ver estadÃ­sticas:")
    print("   python3 test_sistema.py")
    
    print("\nğŸ¯ PrÃ³ximos pasos:")
    print("   1. âœ… Sistema configurado y probado")
    print("   2. âœ… Base de datos lista")
    print("   3. âœ… Interfaz web funcional")
    print("   4. ğŸ”„ Lunes 21/07: Activar scraping automÃ¡tico")
    print("   5. ğŸ“ˆ Monitorear resultados")
    
    return True

def crear_script_inicio():
    """Crear script para iniciar el scraping automÃ¡tico"""
    
    script_content = """#!/bin/bash
# Script para iniciar el scraping automÃ¡tico de noticias jurÃ­dicas
# Ejecutar: ./iniciar_scraping.sh

echo "ğŸš€ Iniciando scraping automÃ¡tico de noticias jurÃ­dicas..."
echo "ğŸ“… Fecha: $(date)"
echo "â° Intervalo: 15 minutos"

# Navegar al directorio del proyecto
cd "$(dirname "$0")"

# Verificar que existe el archivo principal
if [ ! -f "backend/main.py" ]; then
    echo "âŒ Error: No se encuentra backend/main.py"
    exit 1
fi

# Verificar variables de entorno
if [ ! -f "APIS_Y_CREDENCIALES.env" ]; then
    echo "âŒ Error: No se encuentra APIS_Y_CREDENCIALES.env"
    exit 1
fi

# Iniciar scraping en background
echo "ğŸ”„ Iniciando proceso en background..."
nohup python3 backend/main.py --scheduled > scraping.log 2>&1 &

# Guardar PID del proceso
echo $! > scraping.pid

echo "âœ… Scraping iniciado con PID: $(cat scraping.pid)"
echo "ğŸ“‹ Para ver logs: tail -f scraping.log"
echo "ğŸ›‘ Para detener: ./detener_scraping.sh"
"""
    
    with open('iniciar_scraping.sh', 'w') as f:
        f.write(script_content)
    
    # Hacer ejecutable
    os.system('chmod +x iniciar_scraping.sh')
    
    print("âœ… Script de inicio creado: iniciar_scraping.sh")

def crear_script_detencion():
    """Crear script para detener el scraping automÃ¡tico"""
    
    script_content = """#!/bin/bash
# Script para detener el scraping automÃ¡tico de noticias jurÃ­dicas
# Ejecutar: ./detener_scraping.sh

echo "ğŸ›‘ Deteniendo scraping automÃ¡tico..."

# Verificar si existe el archivo PID
if [ ! -f "scraping.pid" ]; then
    echo "âŒ No se encuentra archivo PID. El proceso puede no estar ejecutÃ¡ndose."
    exit 1
fi

# Leer PID
PID=$(cat scraping.pid)

# Verificar si el proceso estÃ¡ ejecutÃ¡ndose
if ps -p $PID > /dev/null; then
    echo "ğŸ”„ Deteniendo proceso con PID: $PID"
    kill $PID
    
    # Esperar un momento y verificar
    sleep 2
    if ps -p $PID > /dev/null; then
        echo "âš ï¸  Proceso no se detuvo, forzando terminaciÃ³n..."
        kill -9 $PID
    fi
    
    echo "âœ… Proceso detenido exitosamente"
else
    echo "âš ï¸  Proceso con PID $PID no estÃ¡ ejecutÃ¡ndose"
fi

# Limpiar archivo PID
rm -f scraping.pid

echo "ğŸ“‹ Logs disponibles en: scraping.log"
"""
    
    with open('detener_scraping.sh', 'w') as f:
        f.write(script_content)
    
    # Hacer ejecutable
    os.system('chmod +x detener_scraping.sh')
    
    print("âœ… Script de detenciÃ³n creado: detener_scraping.sh")

def main():
    """FunciÃ³n principal"""
    
    print("ğŸ”§ CONFIGURACIÃ“N DE SCRAPING AUTOMÃTICO")
    print("=" * 60)
    
    # Configurar sistema
    configurar_scraping_automatico()
    
    # Crear scripts de control
    print("\nğŸ“ Creando scripts de control...")
    crear_script_inicio()
    crear_script_detencion()
    
    print("\n" + "=" * 60)
    print("âœ… CONFIGURACIÃ“N COMPLETA")
    print("=" * 60)
    print("ğŸ“‹ Resumen:")
    print("   â€¢ Sistema listo para scraping automÃ¡tico")
    print("   â€¢ Inicio: Lunes 21 de julio, 9:00 AM")
    print("   â€¢ Intervalo: 15 minutos")
    print("   â€¢ Scripts de control creados")
    print("")
    print("ğŸš€ Para activar el lunes 21:")
    print("   ./iniciar_scraping.sh")
    print("")
    print("ğŸ“Š Para monitorear:")
    print("   tail -f scraping.log")
    print("")
    print("ğŸ›‘ Para detener:")
    print("   ./detener_scraping.sh")

if __name__ == "__main__":
    main() 