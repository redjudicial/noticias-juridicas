# ğŸš€ Plan de Scraping AutomÃ¡tico - Lunes 21 de Julio

## ğŸ“… **Cronograma de ImplementaciÃ³n**

### âœ… **Completado (27 de Julio)**
- [x] Sistema de noticias jurÃ­dicas implementado
- [x] Base de datos Supabase configurada
- [x] Interfaz web funcional con bÃºsqueda y filtros
- [x] Scripts de control creados
- [x] Sistema de logs configurado

### ğŸ”„ **Lunes 21 de Julio - 9:00 AM**
- [ ] Activar scraping automÃ¡tico
- [ ] Monitorear primera ejecuciÃ³n
- [ ] Verificar logs y mÃ©tricas

---

## ğŸ¯ **ConfiguraciÃ³n del Sistema**

### â° **ProgramaciÃ³n**
- **Inicio**: Lunes 21 de Julio, 9:00 AM
- **Intervalo**: Cada 15 minutos
- **DuraciÃ³n**: Continuo (24/7)
- **Fuentes**: 8 fuentes oficiales chilenas

### ğŸ“Š **Fuentes Configuradas**
1. **Poder Judicial** - Scraper web
2. **Tribunal Constitucional** - Scraper web
3. **Ministerio de Justicia** - RSS feed
4. **FiscalÃ­a** - RSS feed
5. **DefensorÃ­a Penal PÃºblica** - Scraper web
6. **ContralorÃ­a** - RSS feed
7. **Consejo de Defensa del Estado** - RSS feed
8. **Diario Oficial** - Scraper web

---

## ğŸ”§ **Comandos de Control**

### ğŸš€ **Iniciar Scraping AutomÃ¡tico**
```bash
./iniciar_scraping.sh
```

### ğŸ“Š **Monitorear en Tiempo Real**
```bash
tail -f scraping.log
```

### ğŸ›‘ **Detener Scraping**
```bash
./detener_scraping.sh
```

### ğŸ“ˆ **Ver EstadÃ­sticas**
```bash
python3 test_sistema.py
```

---

## ğŸ“‹ **Checklist para el Lunes 21**

### â° **9:00 AM - Inicio**
- [ ] Ejecutar: `./iniciar_scraping.sh`
- [ ] Verificar que el proceso se iniciÃ³ correctamente
- [ ] Revisar logs iniciales: `tail -f scraping.log`

### â° **9:15 AM - Primera VerificaciÃ³n**
- [ ] Verificar que se ejecutÃ³ el primer scraping
- [ ] Revisar noticias nuevas en la base de datos
- [ ] Comprobar que la pÃ¡gina web muestra las noticias

### â° **9:30 AM - Segunda VerificaciÃ³n**
- [ ] Verificar segunda ejecuciÃ³n automÃ¡tica
- [ ] Revisar mÃ©tricas de rendimiento
- [ ] Comprobar logs de errores (si los hay)

### ğŸ“Š **Monitoreo Continuo**
- [ ] Revisar logs cada hora
- [ ] Verificar noticias nuevas en la web
- [ ] Monitorear uso de recursos del sistema

---

## ğŸ“Š **MÃ©tricas a Monitorear**

### ğŸ“ˆ **Rendimiento**
- **Noticias por fuente**: CuÃ¡ntas noticias se extraen de cada fuente
- **Tiempo de ejecuciÃ³n**: DuraciÃ³n de cada ciclo de scraping
- **Tasa de Ã©xito**: Porcentaje de fuentes que responden correctamente
- **Errores**: Tipos y frecuencia de errores

### ğŸ“° **Contenido**
- **Noticias nuevas**: Cantidad de noticias nuevas por dÃ­a
- **Duplicados**: Noticias que ya existen en la base de datos
- **CategorÃ­as**: DistribuciÃ³n de noticias por categorÃ­a
- **Fuentes activas**: QuÃ© fuentes estÃ¡n funcionando correctamente

### ğŸ” **Calidad**
- **ResÃºmenes generados**: CuÃ¡ntos resÃºmenes se generan con IA
- **Contenido completo**: Porcentaje de noticias con contenido completo
- **Enlaces vÃ¡lidos**: URLs que funcionan correctamente

---

## ğŸš¨ **SoluciÃ³n de Problemas**

### âŒ **Si el scraping no inicia**
```bash
# Verificar que el proceso estÃ© ejecutÃ¡ndose
ps aux | grep python3

# Verificar logs
cat scraping.log

# Reiniciar si es necesario
./detener_scraping.sh
./iniciar_scraping.sh
```

### âŒ **Si no hay noticias nuevas**
```bash
# Verificar conexiÃ³n a Supabase
python3 test_sistema.py

# Ejecutar scraping manual
python3 backend/main.py --once

# Revisar logs de errores
grep "ERROR" scraping.log
```

### âŒ **Si la pÃ¡gina web no carga**
```bash
# Verificar que la pÃ¡gina funcione
open noticias.html

# Verificar conexiÃ³n a la base de datos
python3 test_sistema.py
```

---

## ğŸ“ **Contacto y Soporte**

### ğŸ”§ **Comandos de DiagnÃ³stico**
```bash
# Estado del sistema
python3 test_sistema.py

# Logs recientes
tail -20 scraping.log

# EstadÃ­sticas de la base de datos
python3 -c "
from backend.database.supabase_client import SupabaseClient
import os
from dotenv import load_dotenv
load_dotenv('APIS_Y_CREDENCIALES.env')
client = SupabaseClient(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_SERVICE_ROLE_KEY'))
print(f'Total noticias: {client.count_noticias()}')
print(f'Fuentes activas: {len(client.get_fuentes_activas())}')
"
```

### ğŸ“Š **URLs Importantes**
- **PÃ¡gina de Noticias**: `noticias.html`
- **Logs del Sistema**: `scraping.log`
- **Base de Datos**: Supabase Dashboard

---

## ğŸ‰ **Ã‰xito Esperado**

### ğŸ“ˆ **DespuÃ©s de 24 horas**
- **50-100 noticias nuevas** en la base de datos
- **8 fuentes funcionando** correctamente
- **ResÃºmenes generados** para todas las noticias
- **PÃ¡gina web actualizada** automÃ¡ticamente

### ğŸ“ˆ **DespuÃ©s de 1 semana**
- **500-1000 noticias** en la base de datos
- **Sistema estable** funcionando 24/7
- **MÃ©tricas optimizadas** y sin errores
- **Contenido de calidad** para Red Judicial

---

**Estado**: âœ… **SISTEMA LISTO PARA PRODUCCIÃ“N**

*Preparado para activaciÃ³n: Lunes 21 de Julio, 9:00 AM* 